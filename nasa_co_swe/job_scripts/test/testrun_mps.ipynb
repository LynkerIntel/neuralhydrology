{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: ../../config_files/pretrain/pretrain_snotel.yml\n",
      "Using MPS backend\n",
      "2024-06-13 09:42:01,204: Logging to /Users/joshsturtevant/Documents/lynker/projects/nasa_water/neuralhydrology/nasa_co_swe/job_scripts/test/runs/pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4_1306_094201/output.log initialized.\n",
      "2024-06-13 09:42:01,204: ### Folder structure created at /Users/joshsturtevant/Documents/lynker/projects/nasa_water/neuralhydrology/nasa_co_swe/job_scripts/test/runs/pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4_1306_094201\n",
      "2024-06-13 09:42:01,205: ### Run configurations for pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4\n",
      "2024-06-13 09:42:01,205: experiment_name: pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4\n",
      "2024-06-13 09:42:01,206: train_basin_file: ../../basin_txt_files/excluding_co_camels_basins_531.txt\n",
      "2024-06-13 09:42:01,206: validation_basin_file: ../../basin_txt_files/co_camels_basins.txt\n",
      "2024-06-13 09:42:01,207: test_basin_file: ../../basin_txt_files/co_camels_basins.txt\n",
      "2024-06-13 09:42:01,207: seed: 4\n",
      "2024-06-13 09:42:01,208: train_start_date: 2000-10-01 00:00:00\n",
      "2024-06-13 09:42:01,208: train_end_date: 2009-09-30 00:00:00\n",
      "2024-06-13 09:42:01,209: validation_start_date: 2012-10-01 00:00:00\n",
      "2024-06-13 09:42:01,209: validation_end_date: 2013-09-30 00:00:00\n",
      "2024-06-13 09:42:01,209: test_start_date: 2010-10-01 00:00:00\n",
      "2024-06-13 09:42:01,210: test_end_date: 2014-09-30 00:00:00\n",
      "2024-06-13 09:42:01,210: device: mps\n",
      "2024-06-13 09:42:01,211: validate_every: 10\n",
      "2024-06-13 09:42:01,211: validate_n_random_basins: 17\n",
      "2024-06-13 09:42:01,212: metrics: ['NSE', 'KGE', 'Alpha-NSE', 'Beta-NSE', 'Pearson-r', 'RMSE', 'Peak-Timing']\n",
      "2024-06-13 09:42:01,212: model: cudalstm\n",
      "2024-06-13 09:42:01,212: head: regression\n",
      "2024-06-13 09:42:01,213: output_activation: linear\n",
      "2024-06-13 09:42:01,213: hidden_size: 128\n",
      "2024-06-13 09:42:01,214: initial_forget_bias: 3\n",
      "2024-06-13 09:42:01,214: output_dropout: 0.4\n",
      "2024-06-13 09:42:01,214: optimizer: Adam\n",
      "2024-06-13 09:42:01,215: loss: MSE\n",
      "2024-06-13 09:42:01,215: learning_rate: {0: 0.001, 1: 0.0005, 2: 0.0004, 3: 0.0003, 4: 0.0002, 5: 0.0001, 6: 9e-05}\n",
      "2024-06-13 09:42:01,216: batch_size: 256\n",
      "2024-06-13 09:42:01,216: epochs: 10\n",
      "2024-06-13 09:42:01,217: clip_gradient_norm: 1\n",
      "2024-06-13 09:42:01,217: predict_last_n: 1\n",
      "2024-06-13 09:42:01,218: seq_length: 365\n",
      "2024-06-13 09:42:01,218: num_workers: 8\n",
      "2024-06-13 09:42:01,219: log_interval: 5\n",
      "2024-06-13 09:42:01,219: log_tensorboard: True\n",
      "2024-06-13 09:42:01,219: log_n_figures: 20\n",
      "2024-06-13 09:42:01,220: save_weights_every: 5\n",
      "2024-06-13 09:42:01,220: dataset: colorado_swe\n",
      "2024-06-13 09:42:01,221: data_dir: ../../../data\n",
      "2024-06-13 09:42:01,221: forcings: ['nldas']\n",
      "2024-06-13 09:42:01,221: dynamic_inputs: ['PRCP(mm/day)', 'SRAD(W/m2)', 'Tmax(C)', 'Tmin(C)', 'Vp(Pa)', 'co_swe_snotel']\n",
      "2024-06-13 09:42:01,222: target_variables: ['QObs(mm/d)']\n",
      "2024-06-13 09:42:01,222: clip_targets_to_zero: ['QObs(mm/d)']\n",
      "2024-06-13 09:42:01,223: static_attributes: ['prm_pc_sse', 'cly_pc_sav', 'slt_pc_sav', 'snd_pc_sav', 'soc_th_sav', 'kar_pc_sse', 'lka_pc_sse', 'gwt_cm_sav', 'slp_dg_sav', 'ele_mt_sav', 'snw_pc_syr']\n",
      "2024-06-13 09:42:01,223: number_of_basins: 517\n",
      "2024-06-13 09:42:01,224: run_dir: /Users/joshsturtevant/Documents/lynker/projects/nasa_water/neuralhydrology/nasa_co_swe/job_scripts/test/runs/pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4_1306_094201\n",
      "2024-06-13 09:42:01,224: train_dir: /Users/joshsturtevant/Documents/lynker/projects/nasa_water/neuralhydrology/nasa_co_swe/job_scripts/test/runs/pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4_1306_094201/train_data\n",
      "2024-06-13 09:42:01,225: img_log_dir: /Users/joshsturtevant/Documents/lynker/projects/nasa_water/neuralhydrology/nasa_co_swe/job_scripts/test/runs/pretrain_hs128_lossMSE_lr1e-3down_HA_snotel_seed4_1306_094201/img_log\n",
      "2024-06-13 09:42:01,227: ### Device cpu will be used for training\n",
      "2024-06-13 09:42:01,401: Loading basin data into xarray data set.\n",
      "100%|██████████| 517/517 [00:37<00:00, 13.83it/s]\n",
      "2024-06-13 09:42:39,142: Create lookup table and convert to pytorch tensor\n",
      "100%|██████████| 517/517 [00:14<00:00, 36.77it/s]\n",
      "2024-06-13 09:42:54,233: Setting learning rate to 0.0005\n",
      "# Epoch 1:   0%|          | 0/5904 [00:00<?, ?it/s]Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "run_config_file = \"../../config_files/pretrain/pretrain_snotel.yml\"\n",
    "print('training: ' + run_config_file)\n",
    "\n",
    "# Check if MPS backend is available\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"Using MPS backend\")\n",
    "    \n",
    "    # Start training with MPS backend\n",
    "    start_run(config_file=Path(run_config_file))\n",
    "\n",
    "# Fall back to CUDA if available\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"Using CUDA backend\")\n",
    "    \n",
    "    # Start training with CUDA backend\n",
    "    start_run(config_file=Path(run_config_file))\n",
    "\n",
    "# Fall back to CPU-only mode\n",
    "else:\n",
    "    print(\"Using CPU backend\")\n",
    "    \n",
    "    # Start training with CPU backend\n",
    "    start_run(config_file=Path(run_config_file), gpu=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate run on test set\n",
    "The run directory that needs to be specified for evaluation is printed in the output log above. Since the folder name is created dynamically (including the date and time of the start of the run) you will need to change the `run_dir` argument according to your local directory name. By default, it will use the same device as during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/test_run_30_colorado_hydroatlas_basin_1106_095251\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#eval_run(run_dir=run_dir, period=\"test\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43meval_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/lynker/projects/nasa_water/neuralhydrology/neuralhydrology/nh_run.py:169\u001b[0m, in \u001b[0;36meval_run\u001b[0;34m(run_dir, period, epoch, gpu)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gpu \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     config\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 169\u001b[0m \u001b[43mstart_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/lynker/projects/nasa_water/neuralhydrology/neuralhydrology/evaluation/evaluate.py:23\u001b[0m, in \u001b[0;36mstart_evaluation\u001b[0;34m(cfg, run_dir, epoch, period)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start evaluation of a trained network\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m tester \u001b[38;5;241m=\u001b[39m get_tester(cfg\u001b[38;5;241m=\u001b[39mcfg, run_dir\u001b[38;5;241m=\u001b[39mrun_dir, period\u001b[38;5;241m=\u001b[39mperiod, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_all_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_all_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/lynker/projects/nasa_water/neuralhydrology/neuralhydrology/evaluation/tester.py:177\u001b[0m, in \u001b[0;36mBaseTester.evaluate\u001b[0;34m(self, epoch, save_results, save_all_output, metrics, model, experiment_logger)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/lynker/projects/nasa_water/neuralhydrology/neuralhydrology/evaluation/tester.py:130\u001b[0m, in \u001b[0;36mBaseTester._load_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load weights of a certain (or the last) epoch into the model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     weight_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_weight_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the model weights from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(weight_file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/Documents/lynker/projects/nasa_water/neuralhydrology/neuralhydrology/evaluation/tester.py:122\u001b[0m, in \u001b[0;36mBaseTester._get_weight_file\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get file path to weight file\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     weight_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_epoch*.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     weight_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "run_dir = Path(\"runs/test_run_30_colorado_hydroatlas_basin_1106_095251\")\n",
    "#eval_run(run_dir=run_dir, period=\"test\")\n",
    "\n",
    "eval_run(run_dir=run_dir, period=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect model predictions\n",
    "Next, we load the results file and compare the model predictions with observations. The results file is always a pickled dictionary with one key per basin (even for a single basin). The next-lower dictionary level is the temporal resolution of the predictions. In this case, we trained a model only on daily data ('1D'). Within the temporal resolution, the next-lower dictionary level are `xr`(an xarray Dataset that contains observations and predictions), as well as one key for each metric that was specified in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    results = pickle.load(fp)\n",
    "    \n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data variables in the xarray Dataset are named according to the name of the target variables, with suffix `_obs` for the observations and suffix `_sim` for the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_test_basin = '06614800'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[example_test_basin]['1D']['xr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model predictions vs. the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract observations and simulations\n",
    "qobs = results[example_test_basin]['1D']['xr']['QObs(mm/d)_obs']\n",
    "qsim = results[example_test_basin]['1D']['xr']['QObs(mm/d)_sim']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(qobs['date'], qobs, label=\"streamflow observation\")\n",
    "ax.plot(qsim['date'], qsim, label=\"LSTM prediction\")\n",
    "plt.legend()\n",
    "ax.set_ylabel(\"Discharge (mm/d)\")\n",
    "ax.set_title(f\"Test period on basin {example_test_basin} - NSE {results[example_test_basin]['1D']['NSE']:.3f}\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to compute all metrics that are implemented in the NeuralHydrology package. You will find additional hydrological signatures implemented in `neuralhydrology.evaluation.signatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = metrics.calculate_all_metrics(qobs.isel(time_step=-1), qsim.isel(time_step=-1))\n",
    "for key, val in values.items():\n",
    "    print(f\"{key}: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
